{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets==4.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Conv2D, AveragePooling2D, Reshape, GlobalAveragePooling2D, Conv2DTranspose, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    batch_size = 32\n",
    "\n",
    "    data = data.map(lambda image, target: image)\n",
    "    data = data.map(lambda image: tf.cast(image, tf.float32))\n",
    "\n",
    "    noisy_data = data.map(lambda image: image + tf.random.normal(shape=(28,28,1), mean=0., stddev=40.))\n",
    "    zip_data = tf.data.Dataset.zip((noisy_data, data))\n",
    "\n",
    "    data = zip_data.map(lambda image, target: ((tf.clip_by_value((image/128. -1), -1, 1), (target/128. -1))))\n",
    "    # data = data.map(lambda image, target: (tf.expand_dims(image, axis=-1), tf.expand_dims(target, axis=-1)))\n",
    "    \n",
    "    data.cache()\n",
    "    data = data.shuffle(2000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pic_or_didnt_happen(ds):\n",
    "    # visualize data by plotting images\n",
    "    for img, target in ds:\n",
    "        print(img.shape, target.shape)\n",
    "        plt.imshow(img[0])       \n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(target[0])       \n",
    "        plt.show()\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img, target):\n",
    "    plt.imshow(img[0])       \n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(target[0])       \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 12:42:24.205036: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954b60addfb544808b998c4255de89b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "(32, 28, 28, 1) (32, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOLklEQVR4nO3df6zddX3H8deLcltsgdELtlZg8sMyy0xW9K7IZK4MNMA/RV0IxZBuYbtEaAILyyRsGWjIVscQnTqyKsRqFOImKDFkih2B4bT2FistFCnDVtqUXrEKZY7+fO+P+4Vcyj2fc3vO9/xo389HcnPO+b7P9/t935P7ut9zvp9zzscRIQCHvyN63QCA7iDsQBKEHUiCsANJEHYgiSO7ubOpnhZHaUY3dwmk8or+V7tjlyeqtRV22xdK+oykKZK+GBHLSvc/SjN0ts9vZ5cAClbFyoa1lp/G254i6fOSLpJ0pqTFts9sdXsAOqud1+wLJD0TEc9GxG5J90haVE9bAOrWTthPlPTcuNtbqmWvY3vY9ojtkT3a1cbuALSj42fjI2J5RAxFxNCApnV6dwAaaCfsWyWdPO72SdUyAH2onbCvljTX9qm2p0q6TNL99bQFoG4tD71FxF7bSyV9R2NDb3dFxBO1dQagVm2Ns0fEA5IeqKkXAB3E22WBJAg7kARhB5Ig7EAShB1IgrADSXT18+w49Bx56tuK9fd/+yfF+lsHftWwtuz2y4vrvvmOHxTrODgc2YEkCDuQBGEHkiDsQBKEHUiCsANJMPSGop/dekyx/tHjNra87Y9f8FL5Dne0vGlMgCM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtym245p1hff87nivX9bez7lZ+Xx/BRL47sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+yHuV9fUR5H/+GS25psYVqxun53FOtX33Rtw9oZ960vrtvOGD7eqK2w294kaaekfZL2RsRQHU0BqF8dR/bzIuKFGrYDoIN4zQ4k0W7YQ9J3ba+xPTzRHWwP2x6xPbJHu9rcHYBWtfs0/tyI2Gp7lqQHbT8VEY+Mv0NELJe0XJKO9WD5bA6AjmnryB4RW6vLUUn3SVpQR1MA6tdy2G3PsH3Mq9clfUBSeSwFQM+08zR+tqT7bL+6na9FxH/U0hVqM3renmJ9+hEDbW3/sh9MeKrmNad9ufG0y4yjd1fLYY+IZyX9Xo29AOgght6AJAg7kARhB5Ig7EAShB1Igo+4Hgb2LXxXw9rdC/+1uO4RTf7f/8GPFxfrp12+tlhH/+DIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJpBln97TyVyJPmXlcsb73+e01dnNwpsybW6xf/8WvNKydNa38QdJmHzPd/b0Tmtzj6SZ19AuO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRJpx9mbj6C+ee0qxPuPfezfO/sKC8lj3H73pNy1v+9wff6RYf8un/7vlbaO/cGQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTSjLM3+zx6L8fRN3/inGL9nis+3WQLjf9nz/vm0uKa824r/957m+wZh46mR3bbd9ketb1+3LJB2w/a3lhdzuxsmwDaNZmn8V+SdOEBy26QtDIi5kpaWd0G0Meahj0iHpG044DFiyStqK6vkHRJvW0BqFurr9lnR8S26vrzkmY3uqPtYUnDknSUpre4OwDtavtsfESEpCjUl0fEUEQMDaj8pY8AOqfVsG+3PUeSqsvR+loC0Amthv1+SUuq60skfauedgB0StPX7LbvlrRQ0gm2t0i6SdIySV+3faWkzZIu7WSTh7tds/YV6/Omtv5q6+1f21Ws7312U8vbxqGladgjYnGD0vk19wKgg3i7LJAEYQeSIOxAEoQdSIKwA0mk+YhrPztixp5yvcn/5Dtf/O2GtYGfv1Bct9lHWKccP1isb1nyjmJ95xmN93DM0+U/v7f+84+K9V8t/v1iffCb6xvW9u/cWVz3cMSRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9C178yHuK9af++PPF+n7tL9ZPmdp4LH3zZ36ruK5Urv/573y/WP/ocd9psv3W/eH5lxfr35//uWL96qXva1h76pNnF9edfu+qYv1QxJEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Lw2IQu3XGsB+Ns5/tS2nlrym9nuPUt5THdZuPsndTss/SHam9/N1r+LPy6C8qf49/3ywOnP+wPq2KlXoodnqjGkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuDz7JM05e2nNqw99ZeziuveM+v2Jluf1kJHaMcnZq0u1t/x91cX62dc1Z/j7CVNj+y277I9anv9uGU3295qe231c3Fn2wTQrsk8jf+SpAsnWH57RMyvfh6oty0AdWsa9oh4RNKh95wFwOu0c4Juqe3Hq6f5Mxvdyfaw7RHbI3u0q43dAWhHq2G/Q9LpkuZL2ibptkZ3jIjlETEUEUMDnIgCeqalsEfE9ojYFxH7JX1B0oJ62wJQt5bCbnvOuJsflNR4blwAfaHpOLvtuyUtlHSC7S2SbpK00PZ8SSFpk6SrOtdif/j1u2c3rG245LNN1h6ot5ku+rPN5e8fWP3QvGL9xIcbzz3/sw+VjzX/edGnivWTjnxTsd6O6Sf8pmPb7pWmYY+IxRMsvrMDvQDoIN4uCyRB2IEkCDuQBGEHkiDsQBJ8xLUGzb7SuJkBTynW93Tw275v3D5UrG+8ozy0dvoDPy3WfewxDWtnfrK4qi74v78q1v9k4Q+L9VtmrSnvoMATfhnzoY0jO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTj7JM1c/XzD2t+Ovru4brOvLW42jt7JaZFvmf2jYv2IZSPF+mc/NrdYv2ZmeRy+HZ2cTrqLM5l3DUd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfZJ2vvspoa19R8+pbjuhpWrivXfnXro/s/t5Dg66nXo/pUBOCiEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+w1KI3BS9KHHr66WF869FCxzlh2/d758F8U63M//nKxvq/OZrqk6ZHd9sm2H7L9pO0nbF9bLR+0/aDtjdXlzM63C6BVk3kav1fS9RFxpqT3SLrG9pmSbpC0MiLmSlpZ3QbQp5qGPSK2RcRj1fWdkjZIOlHSIkkrqrutkHRJh3oEUIODes1u+xRJZ0laJWl2RGyrSs9Lmt1gnWFJw5J0lKa33CiA9kz6bLztoyV9Q9J1EfHS+FpEhKQJv6IvIpZHxFBEDA1oWlvNAmjdpMJue0BjQf9qRNxbLd5ue05VnyNptDMtAqiDo8l35tq2xl6T74iI68Ytv1XSLyNime0bJA1GxF+XtnWsB+Nsn99+14eZKccPFus+ekbL235m+KRifffxnR1E+ofz/q1h7bk95d/7Xx4t/63MfrR8rDr+v7Y2rO3f/oviuvtfeaVY71erYqVeih0TTjg9mdfs75V0haR1ttdWy26UtEzS121fKWmzpEtr6BVAhzQNe0Q8KqnR1PQcpoFDBG+XBZIg7EAShB1IgrADSRB2IImm4+x1Ypwd6KzSODtHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKJp2G2fbPsh20/afsL2tdXym21vtb22+rm48+0CaNVk5mffK+n6iHjM9jGS1th+sKrdHhH/1Ln2ANRlMvOzb5O0rbq+0/YGSSd2ujEA9Tqo1+y2T5F0lqRV1aKlth+3fZftmQ3WGbY9Yntkj3a11y2Alk067LaPlvQNSddFxEuS7pB0uqT5Gjvy3zbRehGxPCKGImJoQNPa7xhASyYVdtsDGgv6VyPiXkmKiO0RsS8i9kv6gqQFnWsTQLsmczbeku6UtCEiPjVu+Zxxd/ugpPX1twegLpM5G/9eSVdIWmd7bbXsRkmLbc+XFJI2SbqqA/0BqMlkzsY/Kmmi+Z4fqL8dAJ3CO+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOCK6tzP7F5I2j1t0gqQXutbAwenX3vq1L4neWlVnb2+LiDdPVOhq2N+wc3skIoZ61kBBv/bWr31J9NaqbvXG03ggCcIOJNHrsC/v8f5L+rW3fu1LordWdaW3nr5mB9A9vT6yA+gSwg4k0ZOw277Q9k9tP2P7hl700IjtTbbXVdNQj/S4l7tsj9peP27ZoO0HbW+sLiecY69HvfXFNN6FacZ7+tj1evrzrr9mtz1F0tOS3i9pi6TVkhZHxJNdbaQB25skDUVEz9+AYft9kl6W9OWIeGe17B8l7YiIZdU/ypkR8bE+6e1mSS/3ehrvaraiOeOnGZd0iaQ/VQ8fu0Jfl6oLj1svjuwLJD0TEc9GxG5J90ha1IM++l5EPCJpxwGLF0laUV1fobE/lq5r0FtfiIhtEfFYdX2npFenGe/pY1foqyt6EfYTJT037vYW9dd87yHpu7bX2B7udTMTmB0R26rrz0ua3ctmJtB0Gu9uOmCa8b557FqZ/rxdnKB7o3Mj4l2SLpJ0TfV0tS/F2Guwfho7ndQ03t0ywTTjr+nlY9fq9Oft6kXYt0o6edztk6plfSEitlaXo5LuU/9NRb391Rl0q8vRHvfzmn6axnuiacbVB49dL6c/70XYV0uaa/tU21MlXSbp/h708Qa2Z1QnTmR7hqQPqP+mor5f0pLq+hJJ3+phL6/TL9N4N5pmXD1+7Ho+/XlEdP1H0sUaOyP/P5L+phc9NOjrNEk/qX6e6HVvku7W2NO6PRo7t3GlpOMlrZS0UdL3JA32UW9fkbRO0uMaC9acHvV2rsaeoj8uaW31c3GvH7tCX1153Hi7LJAEJ+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IIn/B8dRMeNCCpQ1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 12:42:29.437514: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-01-04 12:42:29.439862: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "train_ds = preprocess(train_ds)\n",
    "test_ds = preprocess(test_ds)\n",
    "\n",
    "show_pic_or_didnt_happen(train_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # input conv1 = 28x28x1\n",
    "    self.conv1 = Conv2D(12, 3, activation='relu', padding='same')\n",
    "    # output conv1 = 28x28x12\n",
    "    self.pooling1 = MaxPooling2D()\n",
    "    # output pooling1 = 14x14x12\n",
    "    self.conv3 = Conv2D(24, 3, activation='relu', padding='same')\n",
    "    # output conv3 = 14x14x24\n",
    "    self.pooling2 = MaxPooling2D()\n",
    "    # output pooling1 = 7x7x24\n",
    "    self.conv5 = Conv2D(48, 3, activation='relu', padding='same')\n",
    "    # output conv3 = 7x7x48\n",
    "    self.globalpooling = GlobalAveragePooling2D()\n",
    "    # output global pool 48\n",
    "    self.out = Dense(48, activation=\"sigmoid\")\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x, training=False):\n",
    "    x = self.conv1(x)\n",
    "    x = self.pooling1(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.pooling2(x)\n",
    "    x = self.conv5(x)\n",
    "    x = self.globalpooling(x)\n",
    "    x = self.out(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = Dense(196, activation=\"elu\")\n",
    "        self.reshape = Reshape([7, 7, 4])\n",
    "        self.convT1 = Conv2DTranspose(4, (3, 3), strides=2, activation=\"elu\", padding=\"same\")\n",
    "        self.convT2 = Conv2DTranspose(2, (3, 3), strides=2, activation=\"elu\", padding=\"same\")\n",
    "        self.conv = Conv2D(1, (3, 3), strides=1, activation=\"sigmoid\", padding=\"same\")\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.dense(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.convT1(x)\n",
    "        x = self.convT2(x)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "  def __init__(self, optimizer, loss_function):\n",
    "    super().__init__()\n",
    "    self.enc = Encoder()\n",
    "    self.dec = Decoder()\n",
    "\n",
    "    self.metrics_list = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "      tf.keras.metrics.Mean(name=\"loss\")]\n",
    "\n",
    "    self.optimizer = optimizer\n",
    "    self.loss_function = loss_function\n",
    "\n",
    "  @property\n",
    "  def metrics(self):\n",
    "    return self.metrics_list\n",
    "    \n",
    "  def reset_metrics(self):\n",
    "     for metric in self.metrics:\n",
    "        metric.reset_state()\n",
    "\n",
    "  def call(self, input, training=False):\n",
    "    embedding = self.enc(input)\n",
    "    output = self.dec(embedding)\n",
    "    return output\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(self, data):\n",
    "    image, target = data\n",
    "    with tf.GradientTape() as tape: \n",
    "      prediction = self(image, training = True)\n",
    "      loss = self.loss_function(target, prediction)\n",
    "\n",
    "    gradients = tape.gradient(loss, self.trainable_variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
    "    self.metrics[0].update_state(target, prediction)\n",
    "    self.metrics[1].update_state(loss)  \n",
    "    return gradients\n",
    "\n",
    "  @tf.function\n",
    "  def test_step(self, data):\n",
    "    image, target = data\n",
    "    prediction = self(image, training = False)\n",
    "    loss = self.loss_function(target, prediction)\n",
    "    self.metrics[0].update_state(target, prediction)\n",
    "    self.metrics[1].update_state(loss)\n",
    "    return prediction, target\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path):\n",
    "    for epoch in range(epochs):\n",
    "        model.reset_metrics()\n",
    "\n",
    "        for data in tqdm(train_ds, position=0, leave=True):\n",
    "            model.train_step(data)\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar(model.metrics[0].name, model.metrics[0].result(), step=epoch)\n",
    "            tf.summary.scalar(model.metrics[1].name, model.metrics[1].result(), step=epoch)\n",
    "        \n",
    "        print(\"Epoch: \", epoch+1)\n",
    "        print(\"Loss: \", model.metrics[1].result().numpy(), \"Accuracy: \", model.metrics[0].result().numpy(), \"(Train)\")\n",
    "        model.reset_metrics()\n",
    "\n",
    "        for data in tqdm(test_ds, position=0, leave=True):\n",
    "            prediction, target = model.test_step(data)\n",
    "\n",
    "        visualize(prediction, target)\n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar(model.metrics[0].name, model.metrics[0].result(), step=epoch)\n",
    "            tf.summary.scalar(model.metrics[1].name, model.metrics[1].result(), step=epoch)\n",
    "\n",
    "        print(\"Loss: \", model.metrics[1].result().numpy(), \"Accuracy: \", model.metrics[0].result().numpy(), \"(Test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:19<00:00, 97.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Loss:  0.9536769 Accuracy:  0.001591114 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 121.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.92555416 Accuracy:  0.0016920918 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:11<00:00, 159.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n",
      "Loss:  0.92459303 Accuracy:  0.0015932398 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 144.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.9246408 Accuracy:  0.0016920918 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:12<00:00, 154.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n",
      "Loss:  0.92412806 Accuracy:  0.0015932398 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 157.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.92439663 Accuracy:  0.0016920918 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:12<00:00, 150.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n",
      "Loss:  0.92399615 Accuracy:  0.0015932398 (Train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 149.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.9243446 Accuracy:  0.0016920918 (Test)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1681/1875 [00:11<00:01, 142.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_summary_writer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mcreate_file_writer(train_log_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m test_summary_writer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mcreate_file_writer(test_log_path)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m training_loop(autoencoder, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path)\n",
      "\u001b[1;32m/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb Cell 13\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(train_ds, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m train_summary_writer\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mscalar(model\u001b[39m.\u001b[39mmetrics[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname, model\u001b[39m.\u001b[39mmetrics[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mresult(), step\u001b[39m=\u001b[39mepoch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "autoencoder = Autoencoder(optimizer=optimizer, loss_function=loss_function)\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_path = f\"models/{current_time}\"\n",
    "train_log_path = f\"logs/{current_time}/train\"\n",
    "test_log_path = f\"logs/{current_time}/test\"\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_path)\n",
    "training_loop(autoencoder, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6c2068dfe4e214dd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6c2068dfe4e214dd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6afa05d019bf0021cfdd951a280579caaf080683501157ada207acf29e18cb37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
