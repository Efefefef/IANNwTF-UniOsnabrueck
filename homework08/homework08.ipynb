{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-datasets==4.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Conv2D, AveragePooling2D, Reshape, GlobalAveragePooling2D, MaxPooling2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    batch_size = 32\n",
    "    buffer_size = 2000\n",
    "\n",
    "    data = (\n",
    "        data.map(lambda image, target: (tf.cast(image, tf.float32)/256, target))\n",
    "            .map(lambda image, target: (image, image))\n",
    "            .map(lambda image, target: (image + tf.random.normal(shape=(28,28,1), mean=0, stddev=0.1), target))\n",
    "            .map(lambda image, target: (tf.clip_by_value(image, 0, 1), target))\n",
    "    )\n",
    "    \n",
    "    data.cache()\n",
    "    data = (\n",
    "        data.shuffle(buffer_size)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pic_or_didnt_happen(ds):\n",
    "    # visualize data by plotting images\n",
    "    for img, target in ds:\n",
    "        print(img.shape, target.shape)\n",
    "        plt.imshow(img[0])       \n",
    "        plt.show()\n",
    "\n",
    "        plt.imshow(target[0])       \n",
    "        plt.show()\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img, target):\n",
    "    plt.imshow(img[0])       \n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(target[0])       \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1) (32, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 16:42:29.844065: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "train_ds = preprocess(train_ds)\n",
    "test_ds = preprocess(test_ds)\n",
    "\n",
    "show_pic_or_didnt_happen(train_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = Conv2D(64, 3, activation='relu', padding='same') # 28*28*64\n",
    "    self.pooling1 = MaxPooling2D(2) # 14*14*64\n",
    "    self.conv3 = Conv2D(32, 3, activation='relu', padding='same') # 14*14*32\n",
    "    self.pooling2 = MaxPooling2D(2) # 7*7*32\n",
    "    self.conv5 = Conv2D(16, 3, activation='relu', padding='same') # 7*7*16\n",
    "    self.globalpooling = GlobalAveragePooling2D() # 16\n",
    "    self.out = Dense(10, activation=\"relu\")\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x, training=False):\n",
    "    x = self.conv1(x)\n",
    "    x = self.pooling1(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.pooling2(x)\n",
    "    x = self.conv5(x)\n",
    "    x = self.globalpooling(x)\n",
    "    x = self.out(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = Dense(49, activation=\"relu\")\n",
    "        self.reshape = Reshape((7, 7, 1))\n",
    "        self.conv1 = Conv2D(16, 3, activation=\"relu\", padding=\"same\")\n",
    "        self.upsampling1 = UpSampling2D(2)\n",
    "        self.conv2 = Conv2D(32, 3, activation=\"relu\", padding=\"same\")\n",
    "        self.upsampling2 = UpSampling2D(2)\n",
    "        self.conv_output = Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\")\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x, training=False):\n",
    "        x = self.dense(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.upsampling1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.upsampling2(x)\n",
    "        x = self.conv_output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "  def __init__(self, optimizer, loss_function):\n",
    "    super().__init__()\n",
    "    self.enc = Encoder()\n",
    "    self.dec = Decoder()\n",
    "\n",
    "    self.metrics_list = [\n",
    "      tf.keras.metrics.Mean(name=\"loss\")]\n",
    "\n",
    "    self.optimizer = optimizer\n",
    "    self.loss_function = loss_function\n",
    "\n",
    "  @property\n",
    "  def metrics(self):\n",
    "    return self.metrics_list\n",
    "    \n",
    "  def reset_metrics(self):\n",
    "     for metric in self.metrics:\n",
    "        metric.reset_state()\n",
    "\n",
    "  def call(self, input, training=False):\n",
    "    embedding = self.enc(input)\n",
    "    output = self.dec(embedding)\n",
    "    return output\n",
    "\n",
    "  @tf.function\n",
    "  def train_step(self, data):\n",
    "    image, target = data\n",
    "    with tf.GradientTape() as tape: \n",
    "      prediction = self(image, training = True)\n",
    "      loss = self.loss_function(target, prediction)\n",
    "\n",
    "    gradients = tape.gradient(loss, self.trainable_variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients,self.trainable_variables))\n",
    "    self.metrics[0].update_state(loss)  \n",
    "    return gradients\n",
    "\n",
    "  @tf.function\n",
    "  def test_step(self, data):\n",
    "    image, target = data\n",
    "    prediction = self(image, training = False)\n",
    "    loss = self.loss_function(target, prediction)\n",
    "    self.metrics[0].update_state(loss)\n",
    "    return prediction, target\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path):\n",
    "    for epoch in range(epochs):\n",
    "        model.reset_metrics()\n",
    "\n",
    "        for data in tqdm(train_ds, position=0, leave=True):\n",
    "            model.train_step(data)\n",
    "\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar(model.metrics[0].name, model.metrics[0].result(), step=epoch)\n",
    "        \n",
    "        print(\"Epoch: \", epoch+1)\n",
    "        print(\"Loss: \", model.metrics[0].result().numpy(), \"(Train)\")\n",
    "        model.reset_metrics()\n",
    "\n",
    "        for data in tqdm(test_ds, position=0, leave=True):\n",
    "            prediction, target = model.test_step(data)\n",
    "\n",
    "        visualize(prediction, target)\n",
    "\n",
    "        with test_summary_writer.as_default():\n",
    "            tf.summary.scalar(model.metrics[0].name, model.metrics[0].result(), step=epoch)\n",
    "\n",
    "        print(\"Loss: \", model.metrics[0].result().numpy(), \"(Test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]2023-01-07 16:26:14.505118: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_32/3465026192.py\", line 30, in train_step  *\n        prediction = self(image, training = True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_fileie7rtxcf.py\", line 10, in tf__call\n        embedding = ag__.converted_call(ag__.ld(self).enc, (ag__.ld(input),), None, fscope)\n    File \"/tmp/__autograph_generated_filevbbqi33l.py\", line 11, in tf____call__\n        x = ag__.converted_call(ag__.ld(self).pooling1, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"autoencoder_27\" (type Autoencoder).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_32/3465026192.py\", line 22, in call  *\n            embedding = self.enc(input)\n        File \"/tmp/ipykernel_32/1130670365.py\", line 16, in __call__  *\n            x = self.pooling1(x)\n        File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n            raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n    \n        ValueError: Input 0 of layer \"max_pooling2d_54\" is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: (32, 28, 28, 1, 64)\n    \n    \n    Call arguments received by layer \"autoencoder_27\" (type Autoencoder):\n      • input=tf.Tensor(shape=(32, 28, 28, 1, 1), dtype=float32)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_summary_writer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mcreate_file_writer(train_log_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m test_summary_writer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mcreate_file_writer(test_log_path)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m training_loop(autoencoder, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path)\n",
      "\u001b[1;32m/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb Cell 13\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(train_ds, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m train_summary_writer\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrey/workspace/IANNwTF-UniOsnabrueck/homework08/homework08.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mscalar(model\u001b[39m.\u001b[39mmetrics[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname, model\u001b[39m.\u001b[39mmetrics[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mresult(), step\u001b[39m=\u001b[39mepoch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file9i7vyx0e.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     10\u001b[0m (image, target) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(data)\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m---> 12\u001b[0m     prediction \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), (ag__\u001b[39m.\u001b[39mld(image),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[1;32m     13\u001b[0m     loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mloss_function, (ag__\u001b[39m.\u001b[39mld(target), ag__\u001b[39m.\u001b[39mld(prediction)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m gradients \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileie7rtxcf.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input, training)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m embedding \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39menc, (ag__\u001b[39m.\u001b[39mld(\u001b[39minput\u001b[39m),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdec, (ag__\u001b[39m.\u001b[39mld(embedding),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filevbbqi33l.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconv1, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 11\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mpooling1, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconv3, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mpooling2, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_32/3465026192.py\", line 30, in train_step  *\n        prediction = self(image, training = True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_fileie7rtxcf.py\", line 10, in tf__call\n        embedding = ag__.converted_call(ag__.ld(self).enc, (ag__.ld(input),), None, fscope)\n    File \"/tmp/__autograph_generated_filevbbqi33l.py\", line 11, in tf____call__\n        x = ag__.converted_call(ag__.ld(self).pooling1, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"autoencoder_27\" (type Autoencoder).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_32/3465026192.py\", line 22, in call  *\n            embedding = self.enc(input)\n        File \"/tmp/ipykernel_32/1130670365.py\", line 16, in __call__  *\n            x = self.pooling1(x)\n        File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 214, in assert_input_compatibility\n            raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n    \n        ValueError: Input 0 of layer \"max_pooling2d_54\" is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: (32, 28, 28, 1, 64)\n    \n    \n    Call arguments received by layer \"autoencoder_27\" (type Autoencoder):\n      • input=tf.Tensor(shape=(32, 28, 28, 1, 1), dtype=float32)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "autoencoder = Autoencoder(optimizer=optimizer, loss_function=loss_function)\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "save_path = f\"models/{current_time}\"\n",
    "train_log_path = f\"logs/{current_time}/train\"\n",
    "test_log_path = f\"logs/{current_time}/test\"\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_path)\n",
    "training_loop(autoencoder, train_ds, test_ds, epochs, train_summary_writer, test_summary_writer, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-59c9e5e2a333f176\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-59c9e5e2a333f176\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6afa05d019bf0021cfdd951a280579caaf080683501157ada207acf29e18cb37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
