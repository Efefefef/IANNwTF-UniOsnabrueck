{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Efefefef/IANNwTF-UniOsnabrueck/blob/main/Homework03_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "sovInNoxNKZY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization function\n",
        "def visualization(train_losses , train_accuracies , test_losses , test_accuracies):\n",
        "    plt.figure()\n",
        "    line1 , = plt.plot(train_losses , \"b-\")\n",
        "    line2 , = plt.plot(test_losses , \"r-\") \n",
        "    line3 , = plt.plot(train_accuracies , \"b:\")\n",
        "    line4 , = plt.plot(test_accuracies , \"r:\") \n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend((line1, line2, line3, line4), (\"training loss\", \"test loss\", \"train accuracy\", \"test accuracy\"))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "D2GXjYbINn1F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "def prepare_mnist_data(mnist_data, batch_size):\n",
        "    mnist_data = mnist_data.map(lambda image, target: (tf.cast(image, tf.float32) / 128. - 1, target))\n",
        "    mnist_data = mnist_data.map(lambda image, target: (tf.reshape(image, (-1,)), target))\n",
        "    mnist_data = mnist_data.map(lambda image, target: (image, tf.one_hot(target, 10)))\n",
        "    mnist_data.cache()\n",
        "    mnist_data = mnist_data.shuffle(1000)\n",
        "    mnist_data = mnist_data.batch(batch_size)\n",
        "    mnist_data = mnist_data.prefetch(tf.data.AUTOTUNE)\n",
        "    return mnist_data"
      ],
      "metadata": {
        "id": "BpLAlXFsNwoB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    # Define the layers of the model\n",
        "    def __init__(self, n_unit):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(n_unit, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(n_unit, activation=tf.nn.relu)\n",
        "        self.out = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "\n",
        "    # Forward pass\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PxMpu336PJSU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training step\n",
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(input)\n",
        "        loss = loss_function(target, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss, predictions\n",
        "\n",
        "# Define the test step\n",
        "def test_step(model, image, target, loss_function):\n",
        "    predictions = model(image)\n",
        "    loss = loss_function(target, predictions)\n",
        "    return loss, predictions"
      ],
      "metadata": {
        "id": "XYTC0Y6aPMTp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "def test(model, test_ds, loss_function):\n",
        "    losses = []\n",
        "    accuracy_aggregator = []\n",
        "    for image, target in test_ds:\n",
        "        loss, predictions = test_step(model, image, target, loss_function)\n",
        "        losses.append(loss)\n",
        "        accuracy_aggregator.append(np.mean(np.argmax(predictions, axis=1) == np.argmax(target, axis=1)))\n",
        "    return tf.reduce_mean(losses), tf.reduce_mean(accuracy_aggregator)"
      ],
      "metadata": {
        "id": "37pH-CuoPWJT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CWvsEOaALZo_"
      },
      "outputs": [],
      "source": [
        "# Define the complete training function\n",
        "def train(model, train_ds, test_ds, epochs, loss_function, optimizer, train_losses, train_accuracies, test_losses, test_accuracies):\n",
        "\n",
        "    # Estimate the loss and accuracy on the train set before training\n",
        "    loss, accuracy = test(model, train_ds, loss_function)\n",
        "    train_losses.append(loss)       \n",
        "    train_accuracies.append(accuracy)\n",
        "\n",
        "    # Estimate the loss and accuracy on the test set before training\n",
        "    loss, accuracy = test(model, test_ds, loss_function)\n",
        "    test_losses.append(loss)      \n",
        "    test_accuracies.append(accuracy)\n",
        "\n",
        "    print(\"Pretraining, Loss: {}, Accuracy: {}, (Train)\".format(train_losses[-1], train_accuracies[-1])) \n",
        "    print(\"Pretraining, Loss: {}, Accuracy: {}, (Test)\".format(test_losses[-1], test_accuracies[-1])) \n",
        "    \n",
        "    # Train the model\n",
        "    for epoch in range(epochs):\n",
        "        train_accuracy_aggregator = []\n",
        "        losses = []\n",
        "        for image, target in train_ds:\n",
        "            loss, predictions = train_step(model, image, target, loss_function, optimizer)\n",
        "            losses.append(loss)\n",
        "            train_accuracy_aggregator.append(np.mean(np.argmax(predictions, axis=1) == np.argmax(target, axis=1)))\n",
        "\n",
        "        # Estimate the loss and accuracy on the train set after training    \n",
        "        train_losses.append(tf.reduce_mean(losses))\n",
        "        train_accuracies.append(tf.reduce_mean(train_accuracy_aggregator))\n",
        "\n",
        "        # Estimate the loss and accuracy on the test set after each epoch\n",
        "        loss, accuracy = test(model, train_ds, loss_function)\n",
        "        test_losses.append(loss)         \n",
        "        test_accuracies.append(accuracy)\n",
        "\n",
        "        print(\"Epoch: {}, Loss: {}, Accuracy: {}, (Train)\".format(epoch + 1, train_losses[-1], train_accuracies[-1])) \n",
        "        print(\"Epoch: {}, Loss: {}, Accuracy: {}, (Test)\".format(epoch + 1, test_losses[-1], test_accuracies[-1])) \n",
        "\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.1\n",
        "batch_size = 32\n",
        "n_unit = 256\n",
        "\n",
        "model = MyModel(n_unit)\n",
        "(train_ds, test_ds), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "train_losses , train_accuracies , test_losses , test_accuracies = [], [], [], []\n",
        "\n",
        "train_losses, train_accuracies, test_losses ,test_accuracies = train(\n",
        "    model = model, \n",
        "    train_ds= prepare_mnist_data(train_ds, batch_size), \n",
        "    test_ds= prepare_mnist_data(test_ds, batch_size), \n",
        "    epochs= num_epochs, \n",
        "    loss_function= tf.keras.losses.CategoricalCrossentropy(), \n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate),\n",
        "    train_losses=train_losses,\n",
        "    train_accuracies=train_accuracies,\n",
        "    test_losses=test_losses,\n",
        "    test_accuracies=test_accuracies\n",
        ")"
      ],
      "metadata": {
        "id": "u5vYW4PYPD1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e811d98c-2790-41b8-f3cf-2b523ca1bec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretraining, Loss: 2.5931396484375, Accuracy: 0.06551666666666667, (Train)\n",
            "Pretraining, Loss: 2.5919454097747803, Accuracy: 0.06569488817891374, (Test)\n",
            "Epoch: 1, Loss: 0.31933099031448364, Accuracy: 0.8993, (Train)\n",
            "Epoch: 1, Loss: 0.13202603161334991, Accuracy: 0.9596833333333333, (Test)\n",
            "Epoch: 2, Loss: 0.13078464567661285, Accuracy: 0.959, (Train)\n",
            "Epoch: 2, Loss: 0.09678088873624802, Accuracy: 0.9689666666666666, (Test)\n",
            "Epoch: 3, Loss: 0.09322050213813782, Accuracy: 0.9700833333333333, (Train)\n",
            "Epoch: 3, Loss: 0.06571328639984131, Accuracy: 0.9790166666666666, (Test)\n",
            "Epoch: 4, Loss: 0.07358229160308838, Accuracy: 0.9767166666666667, (Train)\n",
            "Epoch: 4, Loss: 0.05188214033842087, Accuracy: 0.9834166666666667, (Test)\n",
            "Epoch: 5, Loss: 0.05970402806997299, Accuracy: 0.9806833333333334, (Train)\n",
            "Epoch: 5, Loss: 0.047122322022914886, Accuracy: 0.9848333333333333, (Test)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualization(train_losses, train_accuracies, test_losses, test_accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dgfEqgUDNsTC",
        "outputId": "4eb8fd48-51ee-40bd-c232-f2e632a4e7d4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADJUSTING HYPERPARAMETERS\n",
        "\n",
        "Observation is done by changing only one particular parameter, and having the remaining parameters the same as followings:\n",
        "\n",
        "```\n",
        "learning_rate = 0.1\n",
        "n_unit = 256\n",
        "batch_size = 32\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "isnKw0M_L8Qo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Reducing layer size to from 256 to 32 neurons"
      ],
      "metadata": {
        "id": "4j5DjznzUcMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.1\n",
        "batch_size = 32\n",
        "n_unit = 32 # from 256 to 32 units\n",
        "\n",
        "model = MyModel(n_unit)\n",
        "(train_ds, test_ds), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "train_losses , train_accuracies , test_losses , test_accuracies = [], [], [], []\n",
        "\n",
        "train_losses, train_accuracies, test_losses ,test_accuracies = train(\n",
        "    model = model, \n",
        "    train_ds= prepare_mnist_data(train_ds, batch_size), \n",
        "    test_ds= prepare_mnist_data(test_ds, batch_size), \n",
        "    epochs= num_epochs, \n",
        "    loss_function= tf.keras.losses.CategoricalCrossentropy(), \n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate),\n",
        "    train_losses=train_losses,\n",
        "    train_accuracies=train_accuracies,\n",
        "    test_losses=test_losses,\n",
        "    test_accuracies=test_accuracies\n",
        ")\n",
        "visualization(train_losses, train_accuracies, test_losses, test_accuracies)"
      ],
      "metadata": {
        "id": "yA85ylH4CNWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n"
      ],
      "metadata": {
        "id": "zGJSbvPPGMZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Increasing batch size from 32 to 64"
      ],
      "metadata": {
        "id": "GF-IuGGBYYhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.1\n",
        "batch_size = 64 # from 32 to 64 units\n",
        "n_unit = 256 \n",
        "\n",
        "model = MyModel(n_unit)\n",
        "(train_ds, test_ds), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "train_losses , train_accuracies , test_losses , test_accuracies = [], [], [], []\n",
        "\n",
        "train_losses, train_accuracies, test_losses ,test_accuracies = train(\n",
        "    model = model, \n",
        "    train_ds= prepare_mnist_data(train_ds, batch_size), \n",
        "    test_ds= prepare_mnist_data(test_ds, batch_size), \n",
        "    epochs= num_epochs, \n",
        "    loss_function= tf.keras.losses.CategoricalCrossentropy(), \n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate),\n",
        "    train_losses=train_losses,\n",
        "    train_accuracies=train_accuracies,\n",
        "    test_losses=test_losses,\n",
        "    test_accuracies=test_accuracies\n",
        ")\n",
        "visualization(train_losses, train_accuracies, test_losses, test_accuracies)"
      ],
      "metadata": {
        "id": "OiDbxqAlCbwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n"
      ],
      "metadata": {
        "id": "-AGI5h_uGRVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Increasing learning rate from 0.1 to 0.2"
      ],
      "metadata": {
        "id": "q0flFnNHYQ7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.2  # from 0.1 to 0.2\n",
        "batch_size = 32\n",
        "n_unit = 256\n",
        "\n",
        "model = MyModel(n_unit)\n",
        "(train_ds, test_ds), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "train_losses , train_accuracies , test_losses , test_accuracies = [], [], [], []\n",
        "\n",
        "train_losses, train_accuracies, test_losses ,test_accuracies = train(\n",
        "    model = model, \n",
        "    train_ds= prepare_mnist_data(train_ds, batch_size), \n",
        "    test_ds= prepare_mnist_data(test_ds, batch_size), \n",
        "    epochs= num_epochs, \n",
        "    loss_function= tf.keras.losses.CategoricalCrossentropy(), \n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate),\n",
        "    train_losses=train_losses,\n",
        "    train_accuracies=train_accuracies,\n",
        "    test_losses=test_losses,\n",
        "    test_accuracies=test_accuracies\n",
        ")"
      ],
      "metadata": {
        "id": "CfnsFDm3CkCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n"
      ],
      "metadata": {
        "id": "AdbxpT74GYU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Reducing 2 layers to 1 hidden layer (256 neurons)"
      ],
      "metadata": {
        "id": "r5yUYwwqYHcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating model to only 1 hidden layer\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    # Define the layers of the model\n",
        "    def __init__(self, n_unit):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(n_unit, activation=tf.nn.relu)\n",
        "        # self.dense2 = tf.keras.layers.Dense(n_unit, activation=tf.nn.relu)\n",
        "        self.out = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "\n",
        "    # Forward pass\n",
        "    @tf.function\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        # x = self.dense2(x)\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VfqpUP3DCrLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 0.1\n",
        "batch_size = 32\n",
        "n_unit = 32 # from 256 to 32 units\n",
        "\n",
        "model = MyModel(n_unit)\n",
        "(train_ds, test_ds), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "train_losses , train_accuracies , test_losses , test_accuracies = [], [], [], []\n",
        "\n",
        "train_losses, train_accuracies, test_losses ,test_accuracies = train(\n",
        "    model = model, \n",
        "    train_ds= prepare_mnist_data(train_ds, batch_size), \n",
        "    test_ds= prepare_mnist_data(test_ds, batch_size), \n",
        "    epochs= num_epochs, \n",
        "    loss_function= tf.keras.losses.CategoricalCrossentropy(), \n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate),\n",
        "    train_losses=train_losses,\n",
        "    train_accuracies=train_accuracies,\n",
        "    test_losses=test_losses,\n",
        "    test_accuracies=test_accuracies\n",
        ")\n",
        "visualization(train_losses, train_accuracies, test_losses, test_accuracies)"
      ],
      "metadata": {
        "id": "10QRZZ3iC6pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:**\n",
        "\n"
      ],
      "metadata": {
        "id": "nMiJ8ilCGZS3"
      }
    }
  ]
}